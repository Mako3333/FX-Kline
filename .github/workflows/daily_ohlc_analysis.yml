name: Daily OHLC Analysis

on:
  schedule:
    # 08:15 JST == 23:15 UTC (previous day), Monday-Friday only
    - cron: "15 23 * * 0-4"
  workflow_dispatch:

permissions:
  contents: read
  actions: write

jobs:
  fetch-and-analyze:
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup uv
        uses: astral-sh/setup-uv@v3
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: uv sync --frozen

      - name: Fetch OHLC CSVs
        env:
          PAIRS: "USDJPY EURUSD AUDJPY AUDUSD EURJPY XAUUSD"
          INTERVALS: "1h 4h 1d"
          PERIOD_MAP: "1h:10d 4h:35d 1d:200d"
        run: |
          uv run python - <<'PY'
          import os
          import sys
          from pathlib import Path

          sys.path.insert(0, str(Path.cwd() / "src"))

          from fx_kline.core import OHLCRequest, export_to_csv, fetch_batch_ohlc_sync  # type: ignore

          pairs = os.environ["PAIRS"].split()
          intervals = os.environ["INTERVALS"].split()
          period_map_str = os.environ["PERIOD_MAP"]

          period_map = {}
          for item in period_map_str.split():
              if ":" not in item:
                  continue
              key, val = item.split(":", 1)
              period_map[key.strip()] = val.strip()

          missing = [i for i in intervals if i not in period_map]
          if missing:
              raise SystemExit(f"Missing period mapping for intervals: {', '.join(missing)}")

          requests = [
              OHLCRequest(pair=p, interval=i, period=period_map[i])
              for p in pairs
              for i in intervals
          ]

          response = fetch_batch_ohlc_sync(requests)

          csv_dir = Path("csv_data")
          csv_dir.mkdir(parents=True, exist_ok=True)

          success = 0
          for ohlc in response.successful:
              out_path = csv_dir / f"{ohlc.pair}_{ohlc.interval}_{ohlc.period}.csv"
              out_path.write_text(export_to_csv(ohlc), encoding="utf-8")
              success += 1
              print(f"[OK] {out_path.name} rows={ohlc.data_count}")

          for err in response.failed:
              print(f"[ERR] {err.pair}_{err.interval}_{err.period}: {err.error_type} -> {err.error_message}")

          if response.failed:
              raise SystemExit(f"Failed {len(response.failed)} fetch(es) out of {response.total_requested}")

          print(f"Fetched CSVs: {success}/{response.total_requested}")
          PY

      - name: Run analysis aggregator
        run: uv run python ohlc_aggregator.py --input-dir ./csv_data --output-dir ./reports --verbose

      - name: Consolidate analysis summaries
        run: uv run python consolidate_summaries.py --reports-dir ./reports --output-dir ./summary_reports --verbose

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ohlc-daily-${{ github.run_id }}
          path: |
            csv_data/**/*.csv
            reports/**/*.json
            summary_reports/**/*.json
          if-no-files-found: warn
          retention-days: 7
