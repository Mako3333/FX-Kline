name: Daily OHLC Analysis

# このワークフローは以下を行う:
# - トリガー: 平日 08:15 JST の schedule と手動 workflow_dispatch で起動
# - ジョブ: 「Fetch OHLC CSVs」「Run analysis aggregator」「Consolidate analysis summaries」で
#   summary_reports/*_summary.json を生成
# - アーティファクト: 最後に Upload artifacts ステップで CSV/分析結果/summary_reports を Actions Artifact に保存

on:
  schedule:
    # 08:15 JST == 23:15 UTC (previous day), Monday-Friday only
    - cron: "15 23 * * 0-4"
  workflow_dispatch:

permissions:
  # CSV/レポート生成に加えて data/ 配下へのコミットと PR 作成を行うため write 権限を付与
  contents: write
  pull-requests: write
  actions: write

jobs:
  fetch-and-analyze:
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup uv
        uses: astral-sh/setup-uv@v3
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: uv sync --frozen

      - name: Fetch OHLC CSVs
        env:
          PAIRS: "USDJPY EURUSD AUDJPY AUDUSD EURJPY XAUUSD"
          INTERVALS: "1h 4h 1d"
          PERIOD_MAP: "1h:10d 4h:35d 1d:200d"
        run: |
          uv run python - <<'PY'
          import os
          import sys
          from pathlib import Path

          sys.path.insert(0, str(Path.cwd() / "src"))

          from fx_kline.core import OHLCRequest, export_to_csv, fetch_batch_ohlc_sync  # type: ignore

          pairs = os.environ["PAIRS"].split()
          intervals = os.environ["INTERVALS"].split()
          period_map_str = os.environ["PERIOD_MAP"]

          period_map = {}
          for item in period_map_str.split():
              if ":" not in item:
                  continue
              key, val = item.split(":", 1)
              period_map[key.strip()] = val.strip()

          missing = [i for i in intervals if i not in period_map]
          if missing:
              raise SystemExit(f"Missing period mapping for intervals: {', '.join(missing)}")

          requests = [
              OHLCRequest(pair=p, interval=i, period=period_map[i])
              for p in pairs
              for i in intervals
          ]

          response = fetch_batch_ohlc_sync(requests)

          csv_dir = Path("csv_data")
          csv_dir.mkdir(parents=True, exist_ok=True)

          success = 0
          for ohlc in response.successful:
              out_path = csv_dir / f"{ohlc.pair}_{ohlc.interval}_{ohlc.period}.csv"
              out_path.write_text(export_to_csv(ohlc), encoding="utf-8")
              success += 1
              print(f"[OK] {out_path.name} rows={ohlc.data_count}")

          for err in response.failed:
              print(f"[ERR] {err.pair}_{err.interval}_{err.period}: {err.error_type} -> {err.error_message}")

          if response.failed:
              raise SystemExit(f"Failed {len(response.failed)} fetch(es) out of {response.total_requested}")

          print(f"Fetched CSVs: {success}/{response.total_requested}")
          PY

      - name: Run analysis aggregator
        run: uv run python ohlc_aggregator.py --input-dir ./csv_data --output-dir ./reports --verbose

      - name: Consolidate analysis summaries
        run: uv run python consolidate_summaries.py --reports-dir ./reports --output-dir ./summary_reports --verbose

      # L2 サマリー JSON (summary_reports/*_summary.json) を JST 日付パーティション付き data/YYYY/MM/DD/summaries/ にコピー
      - name: Set RUN_DATE (JST)
        run: |
          TZ=Asia/Tokyo
          echo "RUN_DATE=$(TZ=Asia/Tokyo date +%Y-%m-%d)" >> "$GITHUB_ENV"

      - name: Prepare daily data directory
        run: |
          uv run python scripts/prepare_daily_data.py --date "$RUN_DATE"

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ohlc-daily-${{ github.run_id }}
          path: |
            csv_data/**/*.csv
            reports/**/*.json
            summary_reports/**/*.json
          if-no-files-found: warn
          retention-days: 7

      # data/YYYY/MM/DD/summaries/*.json を含む data/ 配下の変更を専用ブランチにコミットし、PR を自動作成
      - name: Create Pull Request for daily data
        uses: peter-evans/create-pull-request@v6
        with:
          commit-message: "chore: add daily summaries for ${{ env.RUN_DATE }}"
          branch: "data/daily-${{ env.RUN_DATE }}"
          title: "chore: add daily summaries for ${{ env.RUN_DATE }}"
          body: |
            This PR adds daily summary JSON files under data/${{ env.RUN_DATE }}/summaries.

            - Generated by the Daily OHLC Analysis workflow
            - Source L2 outputs: summary_reports/*_summary.json
          add-paths: |
            data/
